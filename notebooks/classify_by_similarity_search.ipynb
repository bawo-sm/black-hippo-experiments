{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1856a34a",
   "metadata": {},
   "source": [
    "# Info\n",
    "\n",
    "W skrócie:\n",
    "- zrobiłem zestaw emebddingów na przedmiotach\n",
    "- nowy przedmiot tranformuję na embedding\n",
    "- szukam najbardziej podobnego przedmiotu w przygotowanym zestawie\n",
    "- przydzielam klasę nowemu przedmiotowi wg tego najbardziej podobnego\n",
    "\n",
    "Ze szczegółami:\n",
    "- podzieliłem excela na dane test (1000 wierszy) i train (reszta, ok 3tys) tak żeby zachwoać proprocje w klasie `main`\n",
    "- z danych `train` zrobiłem bazę embeddingów:\n",
    "    - akapit tekstowy złożony z `supplier_name`, `supplier_reference_description` i `purchase_price`\n",
    "    - model generujące embeddingi to klasyczny `sentence-transformers/all-mpnet-base-v2`\n",
    "- dla każdego wiersza w danych `test`\n",
    "    - tworzę analogiczny akapit tekstowy\n",
    "    - w bazie mebeddingów wybieram najbardziej podbny wg metryki `cosine`\n",
    "    - biorę predykcję klasy `main`\n",
    "    - zawężam zestaw bazowy/treningowy do wierszy z podaną klasą `main`\n",
    "    - szukam jeszcze raz najbardziej podobnego embeddingu i wybeiram klasę `sub`\n",
    "    - zawężam  zestaw bazowy/treningowy do wierszy z podaną klasą `sub` i analogicznie szukam kalsy `details`\n",
    "    - powtarzam zawężanie i szukanie aby znalaźeć ostatnią klasę `level4`\n",
    "\n",
    "Metryka poprawności klasyfikacji:\n",
    "- odsetek poprawnie zaklasyfikowanych przedmiotó ze zbioru `test`\n",
    "\n",
    "Ograniczenia, błędy:\n",
    "- zbiór bazowy/treningowy musi być aktualny w sotsunku do nowych przedmiotów"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f28e4",
   "metadata": {},
   "source": [
    "# Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from numpy import dot, argmax\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "pio.templates.default = \"plotly_dark\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7699a1b",
   "metadata": {},
   "source": [
    "# Parametry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc42e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_CLASSES = [\n",
    "    \"Furniture\",\n",
    "    \"Lighting\",\n",
    "    \"Home Textiles\",\n",
    "    \"Tableware\",\n",
    "    \"Decoration\",\n",
    "    \"Flowers & Plants\"\n",
    "]\n",
    "TEST_ROWS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29ca7c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5322d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(raw_df: pd.DataFrame):\n",
    "    # fill na\n",
    "    df = raw_df[raw_df[\"main\"].isin(MAIN_CLASSES)]\n",
    "    for col in [\"main\", \"sub\", \"detail\", \"level4\"]:\n",
    "        df[col] = df[col].fillna(\"Unspecified\")\n",
    "    \n",
    "    ratios = df[\"main\"].value_counts(normalize=True).to_dict()\n",
    "\n",
    "    df = df.sample(len(df)) # shuffle data\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    for main_class, ratio in ratios.items():\n",
    "        new_df = df[df[\"main\"] == main_class].sample(int(TEST_ROWS*ratio))\n",
    "        test_df = pd.concat([test_df, new_df])\n",
    "\n",
    "    if len(test_df) < TEST_ROWS:\n",
    "        diff = TEST_ROWS - len(test_df)\n",
    "        test_df = pd.concat([\n",
    "            test_df,\n",
    "            df[~(df[\"item_id\"].isin(test_df[\"item_id\"]))].sample(diff)\n",
    "        ])\n",
    "\n",
    "    train_df = df[~(df[\"item_id\"].isin(test_df[\"item_id\"]))]\n",
    "\n",
    "    return test_df, train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322357fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedder(model_id: str) -> SentenceTransformer:\n",
    "    match model_id:\n",
    "        case \"sentence-transformers/all-mpnet-base-v2\":\n",
    "            return SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "        case _:\n",
    "            raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aaf34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding_from_text(\n",
    "        model: SentenceTransformer,\n",
    "        text_data: list[str]\n",
    ") -> list[list[float]]:\n",
    "    results = []\n",
    "    for x in tqdm(text_data):\n",
    "        embedding = model.encode([x])[0]\n",
    "        results.append(embedding)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f1b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_text_input(df: pd.DataFrame, i: int) -> str:\n",
    "    text = f\"\"\"\n",
    "    Supplier name = {df[\"supplier_name\"].iloc[i]}\n",
    "    Product name = {df[\"supplier_reference_description\"].iloc[i]}\n",
    "    Product price = {df[\"purchase_price\"].iloc[i]}\n",
    "    \"\"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a, b) -> float:\n",
    "    return float(dot(a, b)/(norm(a)*norm(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdf364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ratio_df(errors_df: pd.DataFrame, test_df: pd.DataFrame, col: str):\n",
    "    error_ratios = errors_df[col].value_counts(normalize=True).reset_index().rename(columns={\"proportion\": \"ratio_in_errors\"})\n",
    "    test_ratios = test_df[col].value_counts(normalize=True).reset_index().rename(columns={\"proportion\": \"ratio_in_tests\"})\n",
    "    ratios_df = pd.merge(\n",
    "        left=error_ratios,\n",
    "        right=test_ratios,\n",
    "        on=col,\n",
    "        how=\"right\"\n",
    "    ).round(2).fillna(0)\n",
    "    ratios_df[\"diff\"] = ratios_df[\"ratio_in_errors\"] - ratios_df[\"ratio_in_tests\"]\n",
    "    print(f'r Pearson Correlation = {round(ratios_df[[\"ratio_in_errors\", \"ratio_in_tests\"]].corr()[\"ratio_in_tests\"].iloc[0], 3)}')\n",
    "    return ratios_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d208d90",
   "metadata": {},
   "source": [
    "# Predykcje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d42a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"../resources/item data 2026_AW(Sheet1).csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = get_embedder(\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9393e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, train_df = train_test_split(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bceebe",
   "metadata": {},
   "source": [
    "## Embeddingi treninogwe / bazowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a87c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = [\n",
    "    row_to_text_input(train_df, i)\n",
    "    for i in range(len(train_df))\n",
    "]\n",
    "base_embeddings = generate_embedding_from_text(\n",
    "    model=embedder,\n",
    "    text_data=text_inputs\n",
    ")\n",
    "train_df[\"embedding\"] = base_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42458b70",
   "metadata": {},
   "source": [
    "## Embeddingi \"nowych\" przedmiotów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648d2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_inputs = [\n",
    "    row_to_text_input(test_df, i)\n",
    "    for i in range(len(test_df))\n",
    "]\n",
    "test_embeddings = generate_embedding_from_text(\n",
    "    model=embedder,\n",
    "    text_data=text_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb424b2",
   "metadata": {},
   "source": [
    "## Znajdź najbardziej podobne przedmioty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_main, pred_sub, pred_detail, pred_level4 = [], [], [], []\n",
    "for test_idx in tqdm(range(len(test_df))):\n",
    "    embedding = test_embeddings[test_idx]\n",
    "\n",
    "    # main prdiction\n",
    "    sim_scores = [cosine_sim(embedding, x) for x in base_embeddings]\n",
    "    best_idx = argmax(sim_scores)\n",
    "    main = train_df[\"main\"].iloc[best_idx]\n",
    "\n",
    "    # sub prediction\n",
    "    train_df_selected = train_df[train_df[\"main\"] == main]\n",
    "    base_embeddings_selected = train_df_selected[\"embedding\"].to_list()\n",
    "    sim_scores = [cosine_sim(embedding, x) for x in base_embeddings_selected]\n",
    "    best_idx = argmax(sim_scores)\n",
    "    sub = train_df_selected[\"sub\"].iloc[best_idx]\n",
    "\n",
    "    # detail prediction\n",
    "    train_df_selected = train_df_selected[train_df_selected[\"sub\"] == sub]\n",
    "    base_embeddings_selected = train_df_selected[\"embedding\"].to_list()\n",
    "    sim_scores = [cosine_sim(embedding, x) for x in base_embeddings_selected]\n",
    "    best_idx = argmax(sim_scores)\n",
    "    detail = train_df_selected[\"detail\"].iloc[best_idx]\n",
    "\n",
    "    # detail prediction\n",
    "    train_df_selected = train_df_selected[train_df_selected[\"detail\"] == detail]\n",
    "    base_embeddings_selected = train_df_selected[\"embedding\"].to_list()\n",
    "    sim_scores = [cosine_sim(embedding, x) for x in base_embeddings_selected]\n",
    "    best_idx = argmax(sim_scores)\n",
    "    level4 = train_df_selected[\"level4\"].iloc[best_idx]\n",
    "    \n",
    "    pred_main.append(main)\n",
    "    pred_sub.append(sub)\n",
    "    pred_detail.append(detail)\n",
    "    pred_level4.append(level4)\n",
    "\n",
    "test_df[\"pred_main\"] = pred_main\n",
    "test_df[\"pred_sub\"] = pred_sub\n",
    "test_df[\"pred_detail\"] = pred_detail\n",
    "test_df[\"pred_level4\"] = pred_level4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20cfa79",
   "metadata": {},
   "source": [
    "## Oszacuj jakość"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a2cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n = len(test_df)\n",
    "main_success_ratio = len(test_df[test_df[\"main\"] == test_df[\"pred_main\"]]) / test_n\n",
    "sub_success_ratio = len(test_df[test_df[\"sub\"] == test_df[\"pred_sub\"]]) / test_n\n",
    "detail_success_ratio = len(test_df[test_df[\"detail\"] == test_df[\"pred_detail\"]]) / test_n\n",
    "level4_success_ratio = len(test_df[test_df[\"level4\"] == test_df[\"pred_level4\"]]) / test_n\n",
    "total_success_ratio = len(\n",
    "    test_df[(\n",
    "        (test_df[\"main\"] == test_df[\"pred_main\"])\n",
    "        & (test_df[\"sub\"] == test_df[\"pred_sub\"])\n",
    "        & (test_df[\"detail\"] == test_df[\"pred_detail\"])\n",
    "        & (test_df[\"level4\"] == test_df[\"pred_level4\"])\n",
    "    )]\n",
    ") / test_n\n",
    "\n",
    "print(\"main_success_ratio = \", round(main_success_ratio, 3))\n",
    "print(\"sub_success_ratio = \", round(sub_success_ratio, 3))\n",
    "print(\"detail_success_ratio = \", round(detail_success_ratio, 3))\n",
    "print(\"level4_success_ratio = \", round(level4_success_ratio, 3))\n",
    "print(\"total_success_ratio = \", round(total_success_ratio, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e001ea2c",
   "metadata": {},
   "source": [
    "## Wizualziacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd24c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        # orientation=\"h\",\n",
    "        x=[\n",
    "            \"main\",\n",
    "            \"sub\",\n",
    "            \"detail\",\n",
    "            \"level4\",\n",
    "            \"total\"\n",
    "        ],\n",
    "        y=[\n",
    "            main_success_ratio,\n",
    "            sub_success_ratio,\n",
    "            detail_success_ratio,\n",
    "            level4_success_ratio,\n",
    "            total_success_ratio\n",
    "        ],\n",
    "        text=[\n",
    "            main_success_ratio,\n",
    "            sub_success_ratio,\n",
    "            detail_success_ratio,\n",
    "            level4_success_ratio,\n",
    "            total_success_ratio\n",
    "        ],\n",
    "        marker_color=[\n",
    "            \"silver\", \"silver\", \"silver\",\"silver\", \"teal\"\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Successfull predictions\",\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f785fef3",
   "metadata": {},
   "source": [
    "# Analiza błędów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea59a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df = test_df[~(\n",
    "    (test_df[\"main\"] == test_df[\"pred_main\"])\n",
    "    & (test_df[\"sub\"] == test_df[\"pred_sub\"])\n",
    "    & (test_df[\"detail\"] == test_df[\"pred_detail\"])\n",
    "    & (test_df[\"level4\"] == test_df[\"pred_level4\"])\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9781bf93",
   "metadata": {},
   "source": [
    "## Błędy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542018df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(errors_df)):\n",
    "    real_class = f'{errors_df[\"main\"].iloc[i]} / {errors_df[\"sub\"].iloc[i]} / {errors_df[\"detail\"].iloc[i]} / {errors_df[\"level4\"].iloc[i]}'\n",
    "    pred_class = f'{errors_df[\"pred_main\"].iloc[i]} / {errors_df[\"pred_sub\"].iloc[i]} / {errors_df[\"pred_detail\"].iloc[i]} / {errors_df[\"pred_level4\"].iloc[i]}'\n",
    "    print(f\"Real = {real_class}\\nPred = {pred_class}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d8cb41",
   "metadata": {},
   "source": [
    "## Reprezentatywność klas - korelacja proprocji klas w danych z błędami do danych testowych\n",
    "- im wieskza, tym bardziej podobne proprocej klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a2160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ratio_df(errors_df, test_df, \"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa27625",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ratio_df(errors_df, test_df, \"sub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ratio_df(errors_df, test_df, \"detail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5189cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ratio_df(errors_df, test_df, \"level4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
